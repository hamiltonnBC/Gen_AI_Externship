{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning BERT\n",
    "\n",
    "## This notebook serves to fine tune a BERT model. The base model is from HuggingFace."
   ],
   "id": "bdccf3f56ef78c68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### NLP Task: named entity recognition\n",
    "### Dataset: Contract Understanding Atticus Dataset (CUAD)\n",
    "### Loading pre-trained model\n",
    "### Monitor training\n",
    "### Deliverable: Submit the code for fine-tuning, training logs, and a short analysis of the results.\n",
    "### SOURCE: https://medium.com/@vcjayan2013/handling-cuad-dataset-for-legal-entity-extraction-the-bert-way-bee0c9d703e0\n"
   ],
   "id": "b3e50e11bb0b39ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:47.901740Z",
     "start_time": "2025-06-01T21:15:47.897896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re, os, itertools\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import nltk\n",
    "#nltk.download() #https://www.nltk.org/data.html\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Text cleaning function below",
   "id": "8d622289c7980da8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:47.907761Z",
     "start_time": "2025-06-01T21:15:47.905085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#define function for text cleaning\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Use raw strings for regex patterns\n",
    "    text = re.sub(r\"_\", \" \", text, 0)\n",
    "    text = re.sub(r\"-{5,}\", \" \", text, 0)  # match 5 or more dashes\n",
    "    text = re.sub(r\"\\*+\", \"*\", text, 0)\n",
    "    text = re.sub(r\" \\.\\ \", \".\", text, 0)\n",
    "\n",
    "    text = text.strip()\n",
    "    return text\n"
   ],
   "id": "fab72943bfc25e4c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Defining the path. Then we walk to iterate over the files. We get the file names, then we append the file text. Then save a dataframe of this info",
   "id": "fcba12b97f92a43a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Looking at dataframe",
   "id": "6c96bf6f367985b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:48.393972Z",
     "start_time": "2025-06-01T21:15:47.919940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "corpus = \"CUAD_v1/full_contract_txt\"\n",
    "file = []\n",
    "contract = []\n",
    "\n",
    "for i in os.listdir(corpus):\n",
    "    path = f\"{corpus}/{i}\"\n",
    "    if os.path.isfile(path):\n",
    "        file.append(i)\n",
    "        with open(path, 'r', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "            text = clean(text)\n",
    "            contract.append(text)\n",
    "\n",
    "df_final = pd.DataFrame({'file': file, 'contract': contract})"
   ],
   "id": "490168ce146de7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/0lgl11h90m15yr0rhlr9l94h0000gn/T/ipykernel_77145/603832585.py:8: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r\"_\", \" \", text, 0)\n",
      "/var/folders/s8/0lgl11h90m15yr0rhlr9l94h0000gn/T/ipykernel_77145/603832585.py:9: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r\"-{5,}\", \" \", text, 0)  # match 5 or more dashes\n",
      "/var/folders/s8/0lgl11h90m15yr0rhlr9l94h0000gn/T/ipykernel_77145/603832585.py:10: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r\"\\*+\", \"*\", text, 0)\n",
      "/var/folders/s8/0lgl11h90m15yr0rhlr9l94h0000gn/T/ipykernel_77145/603832585.py:11: DeprecationWarning: 'count' is passed as positional argument\n",
      "  text = re.sub(r\" \\.\\ \", \".\", text, 0)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:48.404363Z",
     "start_time": "2025-06-01T21:15:48.400512Z"
    }
   },
   "cell_type": "code",
   "source": "df_final.head(8)",
   "id": "248c248d5dfa3cbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                file  \\\n",
       "0  LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...   \n",
       "1  WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION A...   \n",
       "2  LohaCompanyltd_20191209_F-1_EX-10.16_11917878_...   \n",
       "3  CENTRACKINTERNATIONALINC_10_29_1999-EX-10.3-WE...   \n",
       "4  NELNETINC_04_08_2020-EX-1-JOINT FILING AGREEME...   \n",
       "5  ADAMSGOLFINC_03_21_2005-EX-10.17-ENDORSEMENT A...   \n",
       "6  KIROMICBIOPHARMA,INC_05_11_2020-EX-10.23-CONSU...   \n",
       "7  VEONEER,INC_02_21_2020-EX-10.11-JOINT VENTURE ...   \n",
       "\n",
       "                                            contract  \n",
       "0  EXHIBIT 10.6                                DI...  \n",
       "1  Exhibit 10.26    CONFIDENTIAL TREATMENT HAS BE...  \n",
       "2  Exhibit 10.16 SUPPLY CONTRACT Contract No: Dat...  \n",
       "3  1                                             ...  \n",
       "4  Exhibit 1  JOINT FILING AGREEMENT  The undersi...  \n",
       "5  REDACTED COPY  CONFIDENTIAL TREATMENT REQUESTE...  \n",
       "6  Exhibit 10.23 Corporate Address Fannin South P...  \n",
       "7  Exhibit 10.11  AMENDMENT AND TERMINATION  OF  ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>contract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGRE...</td>\n",
       "      <td>EXHIBIT 10.6                                DI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION A...</td>\n",
       "      <td>Exhibit 10.26    CONFIDENTIAL TREATMENT HAS BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LohaCompanyltd_20191209_F-1_EX-10.16_11917878_...</td>\n",
       "      <td>Exhibit 10.16 SUPPLY CONTRACT Contract No: Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENTRACKINTERNATIONALINC_10_29_1999-EX-10.3-WE...</td>\n",
       "      <td>1                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NELNETINC_04_08_2020-EX-1-JOINT FILING AGREEME...</td>\n",
       "      <td>Exhibit 1  JOINT FILING AGREEMENT  The undersi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADAMSGOLFINC_03_21_2005-EX-10.17-ENDORSEMENT A...</td>\n",
       "      <td>REDACTED COPY  CONFIDENTIAL TREATMENT REQUESTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KIROMICBIOPHARMA,INC_05_11_2020-EX-10.23-CONSU...</td>\n",
       "      <td>Exhibit 10.23 Corporate Address Fannin South P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VEONEER,INC_02_21_2020-EX-10.11-JOINT VENTURE ...</td>\n",
       "      <td>Exhibit 10.11  AMENDMENT AND TERMINATION  OF  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "From the medium article, the author decided to trim to 5000 characters as the agreement date will almost certainly be in that snippet.",
   "id": "5327c52b5bee168c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:48.431277Z",
     "start_time": "2025-06-01T21:15:48.428998Z"
    }
   },
   "cell_type": "code",
   "source": "df_final['contract'] = df_final['contract'].str.slice(0, 5000)",
   "id": "eda75bac5fdee154",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Text Annotation section",
   "id": "9a2c9dc85f59e3f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:15:48.474974Z",
     "start_time": "2025-06-01T21:15:48.454893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "json_file = []\n",
    "\n",
    "for index, row in tqdm(df_final.iterrows(), total=df_final.shape[0]):\n",
    "    text = row['contract']\n",
    "    labels = []  # doing annotation later\n",
    "    json_file.append({'text': text, 'labels': labels})\n",
    "\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "json_path = os.path.join(output_dir, \"json_file.json\")\n",
    "\n",
    "# Write the JSONL (Doccano format)\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    for entry in json_file:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n"
   ],
   "id": "557b4548fe87b970",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 510/510 [00:00<00:00, 75704.10it/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The below section is now working with labels. This should potentially be in a different notebook, but for the sake of this externship I will leave everything in this one.",
   "id": "6c232654d584eb86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T21:21:19.948332Z",
     "start_time": "2025-06-01T21:21:19.897698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"data\"\n",
    "jsonl_file = os.path.join(data_dir, \"doccano\", \"admin.jsonl\")\n",
    "\n",
    "df = pd.read_json(jsonl_file, lines=True)\n",
    "df.head()"
   ],
   "id": "8629795f5fe2c749",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/0lgl11h90m15yr0rhlr9l94h0000gn/T/ipykernel_77145/2999507829.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(jsonl_file, lines=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m data_dir = \u001B[33m\"\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\"\u001B[39m  \u001B[38;5;66;03m# or wherever you keep your files\u001B[39;00m\n\u001B[32m      5\u001B[39m jsonl_file = os.path.join(data_dir, \u001B[33m\"\u001B[39m\u001B[33mdoccano\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33madmin.jsonl\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsonl_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlines\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m df.head()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.13.3/lib/python3.13/site-packages/pandas/io/json/_json.py:815\u001B[39m, in \u001B[36mread_json\u001B[39m\u001B[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001B[39m\n\u001B[32m    813\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n\u001B[32m    814\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m815\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.13.3/lib/python3.13/site-packages/pandas/io/json/_json.py:1023\u001B[39m, in \u001B[36mJsonReader.read\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1021\u001B[39m         data = ensure_str(\u001B[38;5;28mself\u001B[39m.data)\n\u001B[32m   1022\u001B[39m         data_lines = data.split(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1023\u001B[39m         obj = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_combine_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_lines\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1025\u001B[39m     obj = \u001B[38;5;28mself\u001B[39m._get_object_parser(\u001B[38;5;28mself\u001B[39m.data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.13.3/lib/python3.13/site-packages/pandas/io/json/_json.py:1051\u001B[39m, in \u001B[36mJsonReader._get_object_parser\u001B[39m\u001B[34m(self, json)\u001B[39m\n\u001B[32m   1049\u001B[39m obj = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1050\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mframe\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1051\u001B[39m     obj = \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mseries\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1054\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, \u001B[38;5;28mbool\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.13.3/lib/python3.13/site-packages/pandas/io/json/_json.py:1187\u001B[39m, in \u001B[36mParser.parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1185\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m   1186\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1187\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1189\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1190\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.13.3/lib/python3.13/site-packages/pandas/io/json/_json.py:1403\u001B[39m, in \u001B[36mFrameParser._parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1399\u001B[39m orient = \u001B[38;5;28mself\u001B[39m.orient\n\u001B[32m   1401\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1402\u001B[39m     \u001B[38;5;28mself\u001B[39m.obj = DataFrame(\n\u001B[32m-> \u001B[39m\u001B[32m1403\u001B[39m         \u001B[43mujson_loads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1404\u001B[39m     )\n\u001B[32m   1405\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1406\u001B[39m     decoded = {\n\u001B[32m   1407\u001B[39m         \u001B[38;5;28mstr\u001B[39m(k): v\n\u001B[32m   1408\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m ujson_loads(json, precise_float=\u001B[38;5;28mself\u001B[39m.precise_float).items()\n\u001B[32m   1409\u001B[39m     }\n",
      "\u001B[31mValueError\u001B[39m: Expected object or value"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3dd11fbae099d9ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
